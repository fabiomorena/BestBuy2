### model
model_name_or_path: TinyLlama/TinyLlama-1.1B-Chat-v1.0

### method
stage: pt
do_train: true
finetuning_type: full

### dataset
dataset: simple_text  # <- Name aus dataset_info.json
dataset_dir: data
template: llama2
cutoff_len: 64
max_samples: 3
overwrite_cache: true

### output
output_dir: saves/minimal-test
logging_steps: 1
save_steps: 10
overwrite_output_dir: true

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 1
learning_rate: 5.0e-5
max_steps: 2
fp16: false
